import random
import math
import time
import numpy as np
import tensorflow as tf

from environment.hyperParameters import DROP_PENALTY, RHO, DURATION


# branchy style DNN model
class BranchyModel:
    def __init__(self, comp_intensities, accuracy, input_data):
        """
        Args:
            comp_intensities:  computation intensities(total cycles / input data size) for each branches
            accuracy: accuracy table of all branches
            input_data: input data size(bits)
        """
        self.branches_num = len(comp_intensities)
        self.comp_intensities = comp_intensities
        self.accuracy = accuracy
        self.input_data = input_data


# DNN inference service
class Service:
    def __init__(self, name, branchy_model: BranchyModel, max_wait_time, accuracy_limit):
        self.name = name
        self.branchy_model = branchy_model
        self.max_wait_time = max_wait_time
        self.base_model_acc = branchy_model.accuracy[-1]
        self.base_model_ci = branchy_model.comp_intensities[-1]  # computation intensity for main branch
        self.acc_limit = accuracy_limit

 
class Entity:
    def __init__(self, comp_ability: int, service: Service):
        """
        Args:
            comp_ability: computation ability (Flops/s)
            service: DNN inference service
        """
        self.name = ''
        self.comp_ability = comp_ability
        self.service = service
        # remain task size: represented by data size(bits)
        self.remain_task = 0

    def scripted_action(self, duration: int):
        """
        scripted actions that each agents would do every time slot: Reduction of remaining tasks
        Args:
            duration: duration of each time slot

        Returns: None
        """
        #print(self.name, " remain task before: ", self.remain_task)
        self.remain_task -= duration * self.comp_ability
        #print(self.name, " remain task after: ", self.remain_task)
        if self.remain_task < 0:
            self.remain_task = 0


# IoT device
class Agent(Entity):
    def __init__(self, comp_ability: int, service: Service, task_lam=1, drop_penalty=DROP_PENALTY, rho=RHO):
        """
        initialize Agent class
        Args:
            comp_ability: computation ability (Flops/s)
            service: DNN inference service
            task_lam: lambda variable for poisson distribution of task arrival
        """
        super(Agent, self).__init__(comp_ability, service)
        # channel gain
        self.task_lam = task_lam
        # discrete action
        self.action = None
        # accuracy sum is used to calculate average accuracy
        self.acc_sum = 0
        # arrived tasks number for next time slot
        self.arrived_tasks = 0
        # the channel gain id
        self.channel_gain_id = 1
        # transmission rate between agent and BS
        self.trans_rate = 0
        # a boolean variable that indicates whether agent would drop tasks when adopts current action
        #self.is_dropped = False
        # Estimated latency of tasks execution when agent adopts current action
        self.latency = 0
        # penalty time for dropping tasks
        self.drop_penalty = drop_penalty
        # adjust the importance of accuracy
        self.rho = rho
        # variable to indicate whether any tasks are dropped during execution
        self.is_dropped = 0

    def reset(self):
        self.channel_gain_id = 1
        self.acc_sum = 0
        self.remain_task = 0
        self.trans_rate = 0
        self.action = None
        self.latency = 0
        self.is_dropped = 0

    def generate_task(self):
        """
        generate task at the begining of the time slot, arrive data size obey Poisson distribution
        Returns: None
        """
        self.arrived_tasks = np.random.poisson(lam=self.task_lam, size=1)[0]
        if self.arrived_tasks == 0:
            self.generate_task()

    def is_offloaded(self):
        """
        check whether agent offload task to base station
        Returns: a boolean var that indicates whether agent offload task to base station
        """
        b_model = self.service.branchy_model
        return self.action == b_model.branches_num

    def policy_action(self):
        """
        execute action generated by the RL model(policy)
        Returns: None
        """
        b_model = self.service.branchy_model
        self.latency, self.is_dropped = 0, 0
        if not self.is_offloaded():
            # execute locally
            branch_id = self.action  # action indicates the chosen branch id
            comp_intensity = b_model.comp_intensities[branch_id]  # chosen branch's computation intensity
            accuracy = b_model.accuracy[branch_id]  # chosen branch's accuracy
            # update acc_sum
            self.acc_sum += accuracy
            # update task queue
            needed_cycles = comp_intensity * b_model.input_data  # needed cpu cycles for per task
            latencys = [0 for _ in range(self.arrived_tasks)]
            for i in range(self.arrived_tasks):
                latencys[i] = (self.remain_task + needed_cycles) / self.comp_ability
                # if arriving task's wait time is bigger than max wait time then drop it
                if latencys[i] > self.service.max_wait_time:
                    self.is_dropped += 1
                else:
                    self.remain_task += needed_cycles
            self.latency = sum(latencys) / self.arrived_tasks
        else:
            # offload to bs
            self.acc_sum += self.service.base_model_acc
        #print(self.name, "remain_task: ", self.remain_task)


# 5G base station
class BaseStation(Entity):
    def __init__(self, comp_ability: int, service: Service):
        super(BaseStation, self).__init__(comp_ability, service)
        self.name = 'Base Station'
        self.utilization_rate = 0

    def reset(self):
        self.remain_task = 0
        self.utilization_rate = 0

    def policy_action(self, tasks_num, upload_rates):
        """
        base station receives tasks that offloaded by agents
        Args:
            tasks_num: a list show the offloaded task number of each agents
            upload_rates: a list show the upload rates(bits/s) for each agents
        Returns:
            latency_list: a list for latency of each agents
            drop_list: a list of variables used to indicate whether a task has been discarded
        """
        latency_list = []
        agents_num = len(tasks_num)
        drop_list = [0 for _ in range(agents_num)]
        pre_remain_task = self.remain_task
        # the sum of arrived data size of all agents
        input_data_size = self.service.branchy_model.input_data
        data_size_sum = sum(tasks_num) * input_data_size

        for i in range(agents_num):
            # for agent i
            if tasks_num[i] == 0:
                latency_list.append(0)
                continue  # execute locally
            # The following latency calculation is for a single task, so there is an average operation
            data_size = tasks_num[i] * input_data_size
            avg_upload_time = data_size / (upload_rates[i] * 2)
            #print("bs: data_size: ", data_size, "upload_rates: ", upload_rates[i])
            execute_time = input_data_size * self.service.base_model_ci / self.comp_ability  # for a single task
            accumulate_queue_time = pre_remain_task / self.comp_ability
            # average wait time among all newly arrived tasks till current agent's tasks are executed
            cur_avg_wait_time = data_size_sum * self.service.base_model_ci / (2 * self.comp_ability) 
            latency = avg_upload_time + execute_time + accumulate_queue_time + cur_avg_wait_time
            #print("bs: ", avg_upload_time, execute_time, accumulate_queue_time, cur_avg_wait_time, latency)
            if latency > self.service.max_wait_time:
                # TODO: Is the estimation of drop tasks number reasonable?
                drop_list[i] += tasks_num[i] // 2
            else:
                self.remain_task += data_size * self.service.base_model_ci 
            latency_list.append(latency)
        #print(self.name, "remain_task: ", self.remain_task)

        # update utilization rate
        self.utilization_rate = min( (self.remain_task - pre_remain_task) / (self.comp_ability * DURATION), 1 )
        return latency_list, drop_list


class World:
    def __init__(self, agents, bs: BaseStation):
        self.agents = agents
        self.bs = bs
        self.duration = DURATION
        # channel gains are divided to three type, Good:6*10^-13, Normal:4*10^-13, Bad:2*10^-13
        self.channel_gain = [6*pow(10, -13), 4*pow(10, -13), 2*pow(10, -13)]
        # channel gain translation matrix
        self.gain_prob = [[0.3, 0.7, 0], [0.25, 0.5, 0.25], [0, 0.7, 0.3]]
        # white Gaussian noise  -100dBm=10^-13W
        self.white_noise = pow(10, -13)
        # transmit power 20dBm=100mW=0.1W
        self.tran_power = 0.1
        # bandwidth of subchannels (MHz), range from [5, 25]
        self.min_bandwidth = 5
        self.max_bandwidth = 5

    def step(self):
        """
        update state of the world
        Returns: None
        """
        # get updated agents' info
        self.update_trans_rate()  # update trans_rate based on agents who offload tasks to base station

        tasks_to_bs = []
        upload_rates = []

        for agent in self.agents:
            if agent.is_offloaded():
                tasks_to_bs.append(agent.arrived_tasks)
                upload_rates.append(agent.trans_rate)
            else:
                tasks_to_bs.append(0)
                upload_rates.append(0)

        # update state of the world
        for agent in self.agents:
            agent.policy_action()
            # Execute tasks in agent's waiting queue
            agent.scripted_action(self.duration)

        # Execute tasks in base station's waiting queue
        latency, drop_list = self.bs.policy_action(tasks_to_bs, upload_rates)
        self.bs.scripted_action(self.duration)
        # union info
        assert len(latency) == len(self.agents) == len(drop_list)
        for i in range(len(latency)):
            self.agents[i].latency += latency[i]
            self.agents[i].is_dropped += drop_list[i]
        self.update_agents_states()

    def update_agents_states(self):
        self.update_agents_tasks()
        self.update_channel_gain()

    def update_agents_tasks(self):
        for agent in self.agents:
            agent.generate_task()

    def update_channel_gain(self):
        """
        make transition of channel gain based on transition matrix for all agents
        Returns: None
        """
        for agent in self.agents:
            tmp = random.uniform(0, 1)
            accumulate_prob = np.cumsum(self.gain_prob[agent.channel_gain_id])
            for i, acc_p in enumerate(accumulate_prob):
                if acc_p >= tmp:
                    agent.channel_gain_id = i
                    break

    # 5G
    def update_trans_rate(self):
        """
        calculate transmission rate of each agents in the case of SIC decoding
        Returns: None
        """
        # count the number of agents of different channel gain type
        counter = {0: 0, 1: 0, 2: 0}
        for agent in self.agents:
            if agent.is_offloaded():
                counter[agent.channel_gain_id] += 1

        for agent in self.agents: 
            if agent.is_offloaded():
                interference = 0  # interference of other agents that share the same channel
                current_gain = self.channel_gain[agent.channel_gain_id]
                for i in range(agent.channel_gain_id):
                    interference += self.tran_power * self.channel_gain[i] * counter[i]
                SINR = self.tran_power * current_gain / (self.white_noise + interference)
                agent.trans_rate =  self.shannon_equation(SINR)

    def shannon_equation(self, SINR):
        cur_bandwidth = random.uniform(0, 1) * (self.max_bandwidth - self.min_bandwidth) + self.min_bandwidth
        return cur_bandwidth * pow(10, 6) * math.log2(1 + SINR)
